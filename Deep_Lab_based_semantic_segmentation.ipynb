{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep-Lab-based-semantic-segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abinesh-18/Deep-Lab-based-semantic-segmentation/blob/main/Deep_Lab_based_semantic_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6PudDKig9G2"
      },
      "source": [
        "# Gather/unzip data\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "drive.mount('/content/gdrive')\n",
        "!cp /content/gdrive/MyDrive/AdvCV/celeb.zip .\n",
        "!unzip celeb.zip\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRdDL0AQfUMa"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "from tensorflow import keras\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmrsAtObk7q5"
      },
      "source": [
        "img_paths = glob.glob('CelebAMask-HQ/CelebA-HQ-img/*.jpg')\n",
        "mask_paths = glob.glob('CelebAMask-HQ/CelebAMask-HQ-mask-anno/*/*.png', recursive=True)\n",
        "\n",
        "# 18 classes + background (19 total)\n",
        "classes = {\n",
        "    0: 'background',\n",
        "    1: 'cloth',\n",
        "    2: 'ear_r',\n",
        "    3: 'eye_g', \n",
        "    4: 'hair', \n",
        "    5: 'hat', \n",
        "    6: 'l_brow',\n",
        "    7: 'l_ear',\n",
        "    8: 'l_eye', \n",
        "    9: 'l_lip', \n",
        "    10: 'mouth', \n",
        "    11: 'neck', \n",
        "    12: 'neck_l', \n",
        "    13: 'nose', \n",
        "    14: 'r_brow', \n",
        "    15: 'r_ear', \n",
        "    16: 'r_eye', \n",
        "    17: 'skin', \n",
        "    18: 'u_lip',\n",
        "}\n",
        "\n",
        "data = {\n",
        "    'img': {},\n",
        "    'img_annos': {}\n",
        "}\n",
        "\n",
        "# Get image ids (numbers) to identify img + help find annotations\n",
        "ids = []\n",
        "for img_path in img_paths:\n",
        "  s = img_path.split('/')[2]\n",
        "  id = s.split('.')[0]\n",
        "  id = int(id)\n",
        "  ids.append(id)\n",
        "  data['img'][id] = img_path\n",
        "  data['img_annos'][id] = []\n",
        "\n",
        "for mask_path in mask_paths:\n",
        "  id = int((mask_path.split('/')[3]).split('_')[0])\n",
        "  data['img_annos'][id].append(mask_path)\n",
        "\n",
        "for id in ids:\n",
        "  data['img_annos'][id].sort()\n",
        "\n",
        "### Partition data into train/val split\n",
        "ids.sort()\n",
        "train_ids = ids[:int(len(ids)*0.8)]\n",
        "val_ids = ids[int(len(ids)*0.8):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMkJFecph-A7"
      },
      "source": [
        "# Dataset generator\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, list_IDs, imgs, labels, class_names, n_channels, n_classes, batch_size=32, dim=(512,512), shuffle=False):\n",
        "    self.list_IDs = list_IDs\n",
        "    self.imgs = imgs\n",
        "    self.labels = labels\n",
        "    self.class_names = class_names\n",
        "    self.n_channels = n_channels\n",
        "    self.n_classes = n_classes\n",
        "    self.batch_size = batch_size\n",
        "    self.dim = dim\n",
        "    self.shuffle = shuffle\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    # Denotes number of batches per epoch\n",
        "    return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    '''Generate one batch of data'''\n",
        "    # Generate indexes of the batch\n",
        "    indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "    # Find list of IDs\n",
        "    list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "    # Generate data\n",
        "    X,y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "    # Because pixels are going to be very imbalanced, set a class weights distribution for training\n",
        "    # Formula for computing class weights from https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#class_weights\n",
        "    # Sets weights matrix per sample per batch\n",
        "    # w = {0: 0.1,\n",
        "    #  1: 10,\n",
        "    #  2: 10, \n",
        "    #  3: 10, \n",
        "    #  4: 1,\n",
        "    #  5: 10,\n",
        "    #  6: 10,\n",
        "    #  7: 10,\n",
        "    #  8: 10,\n",
        "    #  9: 10,\n",
        "    #  10: 10,\n",
        "    #  11: 10,\n",
        "    #  12: 10,\n",
        "    #  13: 10,\n",
        "    #  14: 10,\n",
        "    #  15: 10,\n",
        "    #  16: 10,\n",
        "    #  17: 0.1,\n",
        "    #  18: 10}\n",
        "    # weights = np.zeros_like(y)\n",
        "    # for b in range(self.batch_size):\n",
        "    #   sample = y[b,:,:,:]\n",
        "    #   sample = sample.squeeze()\n",
        "    #   s_w = np.zeros_like(sample)\n",
        "    #   # print(s_w.shape)\n",
        "    #   for i in range(19):\n",
        "    #     # count = np.sum(sample[:,:,i][sample[:,:,i] == 1]) + 1\n",
        "    #     count = np.sum(sample[sample == i]) + 1\n",
        "    #     w = count/(256*256)\n",
        "    #     # w = ( (1 / count) * ((256*256) / 2.0) )\n",
        "    #     # s_w[:,:,i][sample[:,:,i] == 1] = w[i]\n",
        "    #     s_w[sample == i] = w\n",
        "    #   weights[b,] = np.expand_dims(s_w, -1)\n",
        "    #   # weights[b,] = s_w\n",
        "\n",
        "    # return X,y,weights\n",
        "    return X,y\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    '''Updates indexes after each epoch'''\n",
        "    self.indexes = np.arange(len(self.list_IDs))\n",
        "    if self.shuffle == True:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  def __data_generation(self, list_IDs_temp):\n",
        "    '''Generate data'''\n",
        "    X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "    '''Need to stack all mask images in channel dimension'''\n",
        "    y = np.zeros((self.batch_size, *self.dim, 1))\n",
        "    \n",
        "    for i,ID in enumerate(list_IDs_temp):\n",
        "      img = cv2.imread(self.imgs[ID])\n",
        "      img = cv2.resize(img, self.dim)\n",
        "      # Normalize image\n",
        "      img = cv2.normalize(img, None, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "      X[i,] = img\n",
        "      k = 1\n",
        "      # y1\n",
        "      for j in range(self.n_classes):\n",
        "        class_name = self.class_names[j]\n",
        "        if k < len(self.labels[ID]) and class_name in self.labels[ID][k]:\n",
        "          mask = cv2.imread(self.labels[ID][k], cv2.IMREAD_GRAYSCALE)\n",
        "          mask = cv2.resize(mask, self.dim)\n",
        "          y[i][mask == 255] = j\n",
        "          # mask_img[:,:,j][mask == 255] = 1\n",
        "          k += 1\n",
        "      # y2[i,] = mask_img\n",
        "\n",
        "      # y2\n",
        "      # y2 = np.zeros((self.batch_size, *self.dim, self.n_classes))\n",
        "      # mask_img = np.zeros((*self.dim, self.n_classes))\n",
        "      # # print(mask_img.shape)\n",
        "      # for j in range(self.n_classes):\n",
        "      #   # print(y[i][y[i] == j])\n",
        "      #   idxs = np.where(y[i] == j)[0]\n",
        "      #   # print(idxs)\n",
        "      #   mask_img[...,j][idxs] = 1\n",
        "      #   # print(mask_img[...,j])\n",
        "      # y2[i,] = mask_img\n",
        "        \n",
        "\n",
        "    # y = np.zeros((self.batch_size, *self.dim, self.n_classes))\n",
        "\n",
        "    # for i,ID in enumerate(list_IDs_temp):\n",
        "    #   img = cv2.imread(self.imgs[ID])\n",
        "    #   img = cv2.resize(img, self.dim)\n",
        "    #   # Normalize image\n",
        "    #   img = cv2.normalize(img, None, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "    #   X[i,] = img\n",
        "\n",
        "    #   mask_img = np.zeros((*self.dim, self.n_classes))\n",
        "    #   k = 1\n",
        "    #   for j in range(self.n_classes):\n",
        "    #     class_name = self.class_names[j]\n",
        "    #     if k < len(self.labels[ID]) and class_name in self.labels[ID][k]:\n",
        "    #       mask = cv2.imread(self.labels[ID][k], cv2.IMREAD_GRAYSCALE)\n",
        "    #       mask = cv2.resize(mask, self.dim)\n",
        "    #       mask[mask == 255] = 1\n",
        "    #       # y[i][mask == 255] = j\n",
        "    #       # mask = np.expand_dims(mask, 2)\n",
        "    #       mask_img[:,:,j] = mask\n",
        "    #       k += 1\n",
        "    #   y[i,] = mask_img\n",
        "\n",
        "    return X,y\n",
        "\n",
        "train_generator = DataGenerator(train_ids, data['img'], data['img_annos'], classes, n_channels=3, n_classes=19, batch_size=8, dim=(256,256), shuffle=True)\n",
        "val_generator = DataGenerator(val_ids, data['img'], data['img_annos'], classes, n_channels=3, n_classes=19, batch_size=8, dim=(256,256), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiP8OgBghS24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbde45cf-75d9-4be3-960b-7e96ba1ead75"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "'''\n",
        "================================\n",
        "DeepLab implementation from https://keras.io/examples/vision/deeplabv3_plus/\n",
        "================================\n",
        "'''\n",
        "\n",
        "def convolution_block(\n",
        "    block_input,\n",
        "    num_filters=256,\n",
        "    kernel_size=3,\n",
        "    dilation_rate=1,\n",
        "    padding=\"same\",\n",
        "    use_bias=False,\n",
        "):\n",
        "    x = layers.Conv2D(\n",
        "        num_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        dilation_rate=dilation_rate,\n",
        "        padding=\"same\",\n",
        "        use_bias=use_bias,\n",
        "        kernel_initializer=keras.initializers.HeNormal(),\n",
        "    )(block_input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def DilatedSpatialPyramidPooling(dspp_input):\n",
        "    dims = dspp_input.shape\n",
        "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
        "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
        "    out_pool = layers.UpSampling2D(\n",
        "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "\n",
        "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
        "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
        "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
        "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
        "    output = convolution_block(x, kernel_size=1)\n",
        "    return output\n",
        "\n",
        "def DeeplabV3Plus(image_size, num_classes):\n",
        "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
        "    resnet50 = keras.applications.ResNet50(\n",
        "        weights=\"imagenet\", include_top=False, input_tensor=model_input\n",
        "    )\n",
        "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
        "    x = DilatedSpatialPyramidPooling(x)\n",
        "\n",
        "    input_a = layers.UpSampling2D(\n",
        "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
        "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
        "    x = convolution_block(x)\n",
        "    x = convolution_block(x)\n",
        "    x = layers.UpSampling2D(\n",
        "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
        "    # x = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
        "    # model_output = tf.clip_by_value(x, 0, 1)\n",
        "    return keras.Model(inputs=model_input, outputs=model_output)\n",
        "\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)    \n",
        "with tf.device(device_name):\n",
        "  model = DeeplabV3Plus(image_size=256, num_classes=19)\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/device:GPU:0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_hooomIhnMq"
      },
      "source": [
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "# loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "# https://stackoverflow.com/questions/49284455/keras-custom-function-implementing-jaccard/50832690\n",
        "def jaccard_loss(y_true, y_pred, smooth=100):\n",
        "    \"\"\" Calculates mean of Jaccard distance as a loss function \"\"\"\n",
        "    # y_pred = tf.clip_by_value(y_pred, 0, 1)\n",
        "    y_pred = tf.math.softmax(y_pred, axis=-1)\n",
        "    # intersection = tf.reduce_sum(y_true * y_pred, axis=(1,2))\n",
        "    # sum_ = tf.reduce_sum(y_true + y_pred, axis=(1,2))\n",
        "    intersection = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
        "    sum_ = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "    jd =  (1 - jac) * smooth\n",
        "    return tf.reduce_mean(jd)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "  y_pred = tf.math.softmax(y_pred, axis=-1)\n",
        "  y_pred = y_pred[...,1:]\n",
        "  y_true = y_true[...,1:]\n",
        "  numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=(1,2))\n",
        "  denominator = tf.reduce_sum(y_true + y_pred, axis=(1,2))\n",
        "  # numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n",
        "  # denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
        "  return 1 - (numerator / denominator)\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1e-7):\n",
        "    '''\n",
        "    Dice coefficient for 10 categories. Ignores background pixel label 0\n",
        "    Pass to model as metric during compile statement\n",
        "    '''\n",
        "    y_true_f = K.flatten(K.one_hot(K.cast(y_true, 'int32'), num_classes=19))\n",
        "    y_pred = tf.math.softmax(y_pred, axis=-1)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersect = K.sum(y_true_f * y_pred_f, axis=-1)\n",
        "    denom = K.sum(y_true_f + y_pred_f, axis=-1)\n",
        "    return K.mean((2. * intersect / (denom + smooth)))\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    '''\n",
        "    Dice loss to minimize. Pass to model as loss during compile statement\n",
        "    '''\n",
        "    return 1 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def tversky(y_true, y_pred, smooth=1, alpha=0.7):\n",
        "    # y_pred = tf.clip_by_value(y_pred, 0, 1)\n",
        "    y_pred = tf.math.softmax(y_pred, axis=-1)\n",
        "    true_pos = tf.reduce_sum(y_true * y_pred)\n",
        "    false_neg = tf.reduce_sum(y_true * (1 - y_pred))\n",
        "    false_pos = tf.reduce_sum((1 - y_true) * y_pred)\n",
        "    return (true_pos + smooth) / (true_pos + alpha * false_neg + (1 - alpha) * false_pos + smooth)\n",
        "\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    return 1 - tversky(y_true, y_pred)\n",
        "\n",
        "def focal_tversky_loss(y_true, y_pred, gamma=0.75):\n",
        "    tv = tversky(y_true, y_pred)\n",
        "    return K.pow((1 - tv), gamma)\n",
        "\n",
        "class MeanIOU(tf.keras.metrics.MeanIoU):\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # return super().update_state(tf.argmax(y_true, axis=-1), tf.argmax(y_pred, axis=-1), sample_weight)\n",
        "        return super().update_state(y_true, tf.argmax(y_pred, axis=-1), sample_weight)\n",
        "iou = MeanIOU(19)\n",
        "\n",
        "model.compile(\n",
        "    # optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
        "    optimizer='adam',\n",
        "    # loss=loss,\n",
        "    # loss=jaccard_loss,\n",
        "    loss=dice_coef_loss,\n",
        "    metrics=[\"accuracy\", iou],\n",
        ")\n",
        "\n",
        "# Checkpointing\n",
        "checkpoint_path = 'deeplab_dice'\n",
        "# checkpoint_path = '/content/gdrive/MyDrive/AdvCV/deeplab_celeb'\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "history = model.fit(train_generator, validation_data=val_generator, epochs=10, callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK4zqdD-iqMa"
      },
      "source": [
        "### Prediction tensor (H,W,19) to RGB color coded image (H,W,3)\n",
        "# from google.colab.patches import cv2_imshow\n",
        "'''RGB class mapping'''\n",
        "color_map = {\n",
        "    0: [0,0,0],\n",
        "    1: np.flip([165, 198, 239]),\n",
        "    2: np.flip([168, 31, 5]),\n",
        "    3: np.flip([31, 215, 43]),\n",
        "    4: np.flip([255, 0, 0]),\n",
        "    5: np.flip([221, 7, 188]),\n",
        "    6: np.flip([40, 19, 179]),\n",
        "    7: np.flip([153, 245, 26]),\n",
        "    8: np.flip([39, 10, 112]),\n",
        "    9: np.flip([221, 130, 242]),\n",
        "    10: np.flip([99, 55, 72]),\n",
        "    11: np.flip([28, 231, 244]),\n",
        "    12: np.flip([162, 174, 79]),\n",
        "    13: np.flip([139, 60, 131]),\n",
        "    14: np.flip([246, 176, 47]),\n",
        "    15: np.flip([223, 237, 127]),\n",
        "    16: np.flip([135, 66, 130]),\n",
        "    17: np.flip([255, 0, 0]),\n",
        "    18: np.flip([213, 149, 107])\n",
        "}\n",
        "def color_prediction(prediction):\n",
        "  color_img = np.zeros((256,256,3), dtype='uint8')\n",
        "  for i in range(19):\n",
        "    color_img[prediction == i] = color_map[i]\n",
        "  return color_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4j9GUmSg7ge"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "# model = keras.models.load_model('deeplab_celeb_jaccard')\n",
        "idxs = np.random.randint(len(val_ids), size=10)\n",
        "print(idxs)\n",
        "imgs = []\n",
        "for i in idxs:\n",
        "  x = cv2.imread(data['img'][val_ids[i]])\n",
        "  x = cv2.resize(x, (256,256))\n",
        "  x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
        "  imgs.append(x)\n",
        "\n",
        "  pred_mask = model.predict(np.expand_dims(x, axis=0))\n",
        "  pred_mask = np.squeeze(pred_mask)\n",
        "  pred_mask = np.argmax(pred_mask, axis=-1)\n",
        "\n",
        "  mask_rgb = color_prediction(pred_mask)\n",
        "  mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_BGR2RGB)\n",
        "  imgs.append(mask_rgb)\n",
        "\n",
        "fig = plt.figure(figsize=(20., 20.))\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(5, 4),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.05,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, imgs):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(im)\n",
        "    ax.axes.xaxis.set_visible(False)\n",
        "    ax.axes.yaxis.set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}